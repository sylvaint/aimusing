{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Most of my experience with ML and Deep learning has been with tabular data and NLP.\nHere is a basic vision model with the fastai library in the scope of Part 1 (2022) fastai Deep learning course.\n\nI am using the Breast Cancer CT dataset from Kaggle to train a model https://www.kaggle.com/datasets/sabermalek/bcfpp\nThe dataset has 3 categorical labels:\n- 0 : Cancer\n- 1 : Benign\n- 2 : Normal","metadata":{}},{"cell_type":"code","source":"# import libraries\nimport joblib as jlb\nfrom fastai.vision.all import *","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data\nimages, labels, masks = jlb.load('../input/bcfpp/BCFPP.jlb')\n\n# labels contains 3 classes (0 for Cancer, 1 for Benign and 2 for normal)\n\nimages = np.uint8(images)\n\n# lets see what we got\nprint(f\"images: {images.shape}\")\nprint(f\"labels: {labels.shape}\")\nprint(f\"masks: {masks.shape}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T16:04:45.430346Z","iopub.execute_input":"2022-05-04T16:04:45.430620Z","iopub.status.idle":"2022-05-04T16:05:14.914689Z","shell.execute_reply.started":"2022-05-04T16:04:45.430591Z","shell.execute_reply":"2022-05-04T16:05:14.913878Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"#### We have 3600 Breast CT scans size 384 x 156 with labels and a mask","metadata":{}},{"cell_type":"markdown","source":"### Lets look at an image","metadata":{}},{"cell_type":"code","source":"im = Image.fromarray(images[0])\nim.to_thumb(384)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:51:48.243767Z","iopub.execute_input":"2022-05-04T16:51:48.244588Z","iopub.status.idle":"2022-05-04T16:51:48.258470Z","shell.execute_reply.started":"2022-05-04T16:51:48.244537Z","shell.execute_reply":"2022-05-04T16:51:48.257818Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### And the corresponding mask","metadata":{}},{"cell_type":"code","source":"im = Image.fromarray(np.uint8(masks[0]))\nim.to_thumb(384)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:51:18.559063Z","iopub.execute_input":"2022-05-04T16:51:18.559804Z","iopub.status.idle":"2022-05-04T16:51:18.567677Z","shell.execute_reply.started":"2022-05-04T16:51:18.559757Z","shell.execute_reply":"2022-05-04T16:51:18.566965Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Not sure what to do with the mask data at this point so we will ignore it for now when training our model.","metadata":{}},{"cell_type":"markdown","source":"**Lets look at the distribution of our data labels to see if we are dealing with an unbalanced dataset.**","metadata":{}},{"cell_type":"code","source":"(pd.array(labels)\n .value_counts()\n .to_frame(name='labels')\n .set_axis(['count'], axis=1)\n .rename(index={0:'cancer',1:'benign',2:'normal'})\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:47:21.938688Z","iopub.execute_input":"2022-05-04T16:47:21.938984Z","iopub.status.idle":"2022-05-04T16:47:21.950357Z","shell.execute_reply.started":"2022-05-04T16:47:21.938951Z","shell.execute_reply":"2022-05-04T16:47:21.949684Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Perfectly balanced so no issue there.","metadata":{}},{"cell_type":"markdown","source":"### DataBlock\nWe have not covered DataBlock in depth yet and all the examples involve reading image files from disk.\nThe image data from the Breast CT scan dataset is in the form of a Numpy array.\nWe can use the DataBlock by defining functions for get_items, get_x and get_y.\n\nNot the most elegant solution but at this stage it will get us to a model quickly.\n\nI tried using lambda functions but I got and error with learn.export when I did that.","metadata":{}},{"cell_type":"code","source":"# just return the item index\ndef get_items(i):\n    return i\n\n# return image\ndef get_x(i):\n    return images[i]\n\n# return mapped label\ndef get_y(i):\n    if labels[i] == 0: return \"cancer\"\n    if labels[i] == 1: return \"benign\"\n    if labels[i] == 2: return \"normal\"\n\n#  Build DataBlock and keep 20% of our data for validation set\ndls = DataBlock(\n    blocks=(ImageBlock(cls=PILImageBW), CategoryBlock), \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_items=get_items,\n    get_x=get_x,\n    get_y=get_y,\n    item_tfms=Resize(384)\n).dataloaders(list(range(images.shape[0])))\n\n# look at a few images in our DataBlock\ndls.show_batch(max_n=6)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:28:31.572397Z","iopub.execute_input":"2022-05-04T16:28:31.572655Z","iopub.status.idle":"2022-05-04T16:28:35.442845Z","shell.execute_reply.started":"2022-05-04T16:28:31.572626Z","shell.execute_reply":"2022-05-04T16:28:35.442017Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# build a model from a resnet18\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(6)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:55:41.849603Z","iopub.execute_input":"2022-05-04T16:55:41.849882Z","iopub.status.idle":"2022-05-04T16:57:41.435567Z","shell.execute_reply.started":"2022-05-04T16:55:41.849849Z","shell.execute_reply":"2022-05-04T16:57:41.434723Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# save model for deployment later\nlearn.export('model.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:00:17.352336Z","iopub.execute_input":"2022-05-04T17:00:17.353257Z","iopub.status.idle":"2022-05-04T17:00:17.470292Z","shell.execute_reply.started":"2022-05-04T17:00:17.353210Z","shell.execute_reply":"2022-05-04T17:00:17.469506Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(7,6), cmap='Purples')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:03:49.404649Z","iopub.execute_input":"2022-05-04T17:03:49.404961Z","iopub.status.idle":"2022-05-04T17:03:53.667163Z","shell.execute_reply.started":"2022-05-04T17:03:49.404907Z","shell.execute_reply":"2022-05-04T17:03:53.666330Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"In this classification we are looking to optimize cancer recall.  Misclassifying cancer for benign or benign for cancer is not an issue as a biopsy would most likely be performed to see if cancer is actually present.\nSo the bad outcome would be our model predicting a normal scan when it was actually cancer.\n\nIn our confusion matrix this was only the case for 2 scans !","metadata":{}},{"cell_type":"code","source":"print(f'percent of instances where model predicted normal when cancer was present: {round((2/len(dls.valid_ds))*100,2)}%')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T17:18:10.162446Z","iopub.execute_input":"2022-05-04T17:18:10.162708Z","iopub.status.idle":"2022-05-04T17:18:10.169436Z","shell.execute_reply.started":"2022-05-04T17:18:10.162678Z","shell.execute_reply":"2022-05-04T17:18:10.168561Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"The model missed a cancer diagnosis in only 0.28% of the CT scans!  This is considering that the 78 times our model mislabelled cancer for benign it would have been caught with a biopsy.   ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}