<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>fastai ULMFit approach performance versus standard NLP Pytorch model | AI quant experiments</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="fastai ULMFit approach performance versus standard NLP Pytorch model" />
<meta name="author" content="Sylvain Thibault" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Comparing the performance of ULMFit with a standard NLP Pytorch model for StockTwits message sentiment analysis." />
<meta property="og:description" content="Comparing the performance of ULMFit with a standard NLP Pytorch model for StockTwits message sentiment analysis." />
<link rel="canonical" href="https://sylvaint.dev/ai%20for%20trading/ulmfit/stocktwits/2020/10/20/fastai_ulmfit_vs_pytorch_stocktwits.html" />
<meta property="og:url" content="https://sylvaint.dev/ai%20for%20trading/ulmfit/stocktwits/2020/10/20/fastai_ulmfit_vs_pytorch_stocktwits.html" />
<meta property="og:site_name" content="AI quant experiments" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-20T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://sylvaint.dev/ai%20for%20trading/ulmfit/stocktwits/2020/10/20/fastai_ulmfit_vs_pytorch_stocktwits.html","@type":"BlogPosting","headline":"fastai ULMFit approach performance versus standard NLP Pytorch model","dateModified":"2020-10-20T00:00:00-05:00","datePublished":"2020-10-20T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://sylvaint.dev/ai%20for%20trading/ulmfit/stocktwits/2020/10/20/fastai_ulmfit_vs_pytorch_stocktwits.html"},"author":{"@type":"Person","name":"Sylvain Thibault"},"description":"Comparing the performance of ULMFit with a standard NLP Pytorch model for StockTwits message sentiment analysis.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://sylvaint.dev/feed.xml" title="AI quant experiments" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">AI quant experiments</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">fastai ULMFit approach performance versus standard NLP Pytorch model</h1><p class="page-description">Comparing the performance of ULMFit with a standard NLP Pytorch model for StockTwits message sentiment analysis.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-20T00:00:00-05:00" itemprop="datePublished">
        Oct 20, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Sylvain Thibault</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      26 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#AI for trading">AI for trading</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#ULMFit">ULMFit</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Stocktwits">Stocktwits</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/sylvaint/aimusing/tree/master/_notebooks/2020-10-20-fastai_ulmfit_vs_pytorch_stocktwits.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/sylvaint/aimusing/master?filepath=_notebooks%2F2020-10-20-fastai_ulmfit_vs_pytorch_stocktwits.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/sylvaint/aimusing/blob/master/_notebooks/2020-10-20-fastai_ulmfit_vs_pytorch_stocktwits.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h2"><a href="#PyTorch-NLP-model">PyTorch NLP model </a></li>
<li class="toc-entry toc-h2"><a href="#Import-Twits">Import Twits </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Load-Twits-Data">Load Twits Data </a></li>
<li class="toc-entry toc-h3"><a href="#Length-of-data">Length of data </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Preprocessing-the-Data">Preprocessing the Data </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Preprocess-All-the-Twits">Preprocess All the Twits </a></li>
<li class="toc-entry toc-h3"><a href="#Bag-of-Words">Bag of Words </a></li>
<li class="toc-entry toc-h3"><a href="#Frequency-of-Words-Appearing-in-Message">Frequency of Words Appearing in Message </a></li>
<li class="toc-entry toc-h3"><a href="#Remove-Filtered-Words-from-Vocabulary">Remove Filtered Words from Vocabulary </a></li>
<li class="toc-entry toc-h3"><a href="#Balancing-the-classes">Balancing the classes </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Neural-Network">Neural Network </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Embed-->-RNN-->-Dense-->-Softmax">Embed -&gt; RNN -&gt; Dense -&gt; Softmax </a></li>
<li class="toc-entry toc-h3"><a href="#View-Model">View Model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Training">Training </a>
<ul>
<li class="toc-entry toc-h3"><a href="#DataLoaders-and-Batching">DataLoaders and Batching </a></li>
<li class="toc-entry toc-h3"><a href="#Training-and--Validation">Training and  Validation </a></li>
<li class="toc-entry toc-h3"><a href="#Train-model">Train model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#ULMFit-approach">ULMFit approach </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Import-Twits">Import Twits </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Preprocessing-the-Data">Preprocessing the Data </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Build-dataframe">Build dataframe </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Self-supervized-language-model">Self supervized language model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Text-data-loader">Text data loader </a></li>
<li class="toc-entry toc-h3"><a href="#Look-at-the-data">Look at the data </a></li>
<li class="toc-entry toc-h3"><a href="#Create-language-learner">Create language learner </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Fine-Tuning-the-Language-Model">Fine-Tuning the Language Model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Continue-fine-tuning-the-model-after-unfreezing">Continue fine-tuning the model after unfreezing </a></li>
<li class="toc-entry toc-h3"><a href="#Display-the-RNN-layers">Display the RNN layers </a></li>
<li class="toc-entry toc-h3"><a href="#Test-our-basic-language-model">Test our basic language model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#-">  </a></li>
<li class="toc-entry toc-h2"><a href="#Classifier-for-Stocktwits-sentiments">Classifier for Stocktwits sentiments </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Create-the-data-loader-with-sentiment-labels">Create the data loader with sentiment labels </a></li>
<li class="toc-entry toc-h3"><a href="#Create-the-learner-to-classify-our-"Twits"">Create the learner to classify our &quot;Twits&quot; </a></li>
<li class="toc-entry toc-h3"><a href="#Fine-tuning-the-classifier">Fine tuning the classifier </a></li>
<li class="toc-entry toc-h3"><a href="#Predictions-with-the-ULMFit-model">Predictions with the ULMFit model </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-20-fastai_ulmfit_vs_pytorch_stocktwits.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h2>
<p>In this project we will be comparing the results from a sentiment analysis model using a RNN implemented directly in PyTorch with another using the Fastai library with the ULMFit (Universal Language Model Fine-tuning) approach from this <a href="https://arxiv.org/abs/1801.06146">paper</a> from Jeremy Howard and Sebastian Ruder.</p>
<p>The ULMFit approach involves using a language model first and then train it with the new vocabulary from the new application.  Once our language model has been trained with the added new data, we use it as the base from our classification problem.  A language model is a model that has been trained to guess the next word coming in a text from having seen the words that came before.  This kind of process is called <em>self supervized learning</em>.  In this case, no labels are provided to our model.</p>
<p>Lets move onto the actual classification problem we are going to solve.</p>
<p>When deciding the value of a company, it's important to follow the news. For example, a product recall or natural disaster in a company's product chain. You want to be able to turn this information into a signal.</p>
<p>We will be using posts from the social media site <a href="https://en.wikipedia.org/wiki/StockTwits">StockTwits</a>. The community on StockTwits is full of investors, traders, and entrepreneurs. Each message posted is called a Twit. This is similar to Twitter's version of a post, called a Tweet. We will build a model around these twits that generate a sentiment score.</p>
<p>The data is a large collection of messages that where hand labeled with the sentiment of each.  The degree of sentiment is a five-point scale: very negative, negative, neutral, positive, very positive. Each twit is labeled -2 to 2 in steps of 1, from very negative to very positive respectively.</p>
<p>The first thing we should to do, is load the data.</p>
<h2 id="PyTorch-NLP-model">
<a class="anchor" href="#PyTorch-NLP-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>PyTorch NLP model<a class="anchor-link" href="#PyTorch-NLP-model"> </a>
</h2>
<h2 id="Import-Twits">
<a class="anchor" href="#Import-Twits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Import Twits<a class="anchor-link" href="#Import-Twits"> </a>
</h2>
<h3 id="Load-Twits-Data">
<a class="anchor" href="#Load-Twits-Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load Twits Data<a class="anchor-link" href="#Load-Twits-Data"> </a>
</h3>
<p>This JSON file contains a list of objects for each twit in the <code>'data'</code> field:</p>

<pre><code>{'data':
  {'message_body': 'Neutral twit body text here',
   'sentiment': 0},
  {'message_body': 'Happy twit body text here',
   'sentiment': 1},
   ...
}</code></pre>
<p>The fields represent the following:</p>
<ul>
<li>
<code>'message_body'</code>: The text of the twit.</li>
<li>
<code>'sentiment'</code>: Sentiment score for the twit, ranges from -2 to 2 in steps of 1, with 0 being neutral.</li>
</ul>
<p>To see what the data look like by printing the first 10 twits from the list.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="s1">'stocktwits_sentiment'</span><span class="p">,</span> <span class="s1">'twits.json'</span><span class="p">),</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">twits</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Length-of-data">
<a class="anchor" href="#Length-of-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Length of data<a class="anchor-link" href="#Length-of-data"> </a>
</h3>
<p>Lets look at the length of our data:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">twits</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1548010
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And a couple of messages</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">twits</span><span class="p">[</span><span class="s1">'data'</span><span class="p">][:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[{'message_body': '$FITB great buy at 26.00...ill wait', 'sentiment': 2, 'timestamp': '2018-07-01T00:00:09Z'}, {'message_body': '@StockTwits $MSFT', 'sentiment': 1, 'timestamp': '2018-07-01T00:00:42Z'}, {'message_body': '#STAAnalystAlert for $TDG : Jefferies Maintains with a rating of Hold setting target price at USD 350.00. Our own verdict is Buy  http://www.stocktargetadvisor.com/toprating', 'sentiment': 2, 'timestamp': '2018-07-01T00:01:24Z'}, {'message_body': '$AMD I heard there’s a guy who knows someone who thinks somebody knows something - on StockTwits.', 'sentiment': 1, 'timestamp': '2018-07-01T00:01:47Z'}, {'message_body': '$AMD reveal yourself!', 'sentiment': 0, 'timestamp': '2018-07-01T00:02:13Z'}]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets split the messages and the labels</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">twit</span><span class="p">[</span><span class="s1">'message_body'</span><span class="p">]</span> <span class="k">for</span> <span class="n">twit</span> <span class="ow">in</span> <span class="n">twits</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]]</span>
<span class="c1"># Since the sentiment scores are discrete, we'll scale the sentiments to 0 to 4 for use in our network</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="p">[</span><span class="n">twit</span><span class="p">[</span><span class="s1">'sentiment'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">twit</span> <span class="ow">in</span> <span class="n">twits</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages</span><span class="p">[</span><span class="mi">45</span><span class="p">],</span> <span class="n">sentiments</span><span class="p">[</span><span class="mi">45</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('$NFLX just noticed they have the last jedi on stream. Love this stock', 2)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocessing-the-Data">
<a class="anchor" href="#Preprocessing-the-Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing the Data<a class="anchor-link" href="#Preprocessing-the-Data"> </a>
</h2>
<p>With our data in hand we need to preprocess our text. These twits are collected by filtering on ticker symbols where these are denoted with a leader $ symbol in the twit itself. For example,</p>
<p><code>{'message_body': 'RT @google Our annual look at the year in Google blogging (and beyond) http://t.co/sptHOAh8 $GOOG',
 'sentiment': 0}</code></p>
<p>The ticker symbols don't provide information on the sentiment, and they are in every twit, so we should remove them. This twit also has the <code>@google</code> username, again not providing sentiment information, so we should also remove it. We also see a URL <code>http://t.co/sptHOAh8</code>. Let's remove these too.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'wordnet'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">preprocess_1</span><span class="p">(</span><span class="n">message</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    This function takes a string as input, then performs these operations: </span>
<span class="sd">        - lowercase</span>
<span class="sd">        - remove URLs</span>
<span class="sd">        - remove ticker symbols </span>
<span class="sd">        - removes punctuation</span>
<span class="sd">        - tokenize by splitting the string on whitespace </span>
<span class="sd">        - removes any single character tokens</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        message : The text message to be preprocessed.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        tokens: The preprocessed text into tokens.</span>
<span class="sd">    """</span> 
    <span class="c1"># Lowercase the twit message</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">message</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    
    <span class="c1"># Replace URLs with a space in the message</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'https?://[^\s]+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\$[a-z]*\b'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Replace StockTwits usernames with a space. The usernames are any word that starts with @.</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'@\w*\b'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># Replace everything not a letter with a space</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^a-z]'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Tokenize by splitting the string on whitespace into a list of words</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="c1"># Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.</span>
    <span class="n">wnl</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">WordNetLemmatizer</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">wnl</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">tokens</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data]   Unzipping corpora/wordnet.zip.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-All-the-Twits">
<a class="anchor" href="#Preprocess-All-the-Twits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocess All the Twits<a class="anchor-link" href="#Preprocess-All-the-Twits"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">preprocess_1</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenized</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">messages</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>([['great', 'buy', 'at', 'ill', 'wait']],
 ['$FITB great buy at 26.00...ill wait'])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking good</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets check for empty tokens</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">([</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenized</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>48528</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Clean that up</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">good_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokenized</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenized</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">good_tokens</span><span class="p">]</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentiments</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">good_tokens</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Bag-of-Words">
<a class="anchor" href="#Bag-of-Words" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bag of Words<a class="anchor-link" href="#Bag-of-Words"> </a>
</h3>
<p>Now with all of our messages tokenized, we want to create a vocabulary and count up how often each word appears in our entire corpus.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="sd">"""</span>
<span class="sd">Create a vocabulary by using Bag of words</span>
<span class="sd">"""</span>
<span class="n">stacked_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">twit</span> <span class="ow">in</span> <span class="n">tokenized</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">twit</span><span class="p">]</span>

<span class="n">bow</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">stacked_tokens</span><span class="p">)</span>
<span class="c1"># sort by decreasing order</span>
<span class="n">sorted_bow</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">bow</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">bow</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Frequency-of-Words-Appearing-in-Message">
<a class="anchor" href="#Frequency-of-Words-Appearing-in-Message" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency of Words Appearing in Message<a class="anchor-link" href="#Frequency-of-Words-Appearing-in-Message"> </a>
</h3>
<p>With our vocabulary parsed, lets remove some of the most common words such as 'the', 'and', 'it', etc. These words don't contribute to identifying sentiment and are really common, resulting in a lot of noise in our input. If we can filter these out, then our network should have an easier time learning.</p>
<p>We also want to remove really rare words that show up only in a few twits. Here you'll want to divide the count of each word by the number of messages. Then remove words that only appear in some small fraction of the messages.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># The key is the token and the value is the frequency of that word in the corpus.</span>
<span class="n">total_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bow</span><span class="p">)</span>

<span class="n">freqs</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">count</span><span class="o">/</span><span class="n">total_words</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">bow</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1"># Float that is the frequency cutoff. Drop words with a frequency that is lower or equal to this number.</span>
<span class="n">low_cutoff</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="c1"># Integer that is the cut off for most common words. Drop words that are the `high_cutoff` most common words.</span>
<span class="n">high_cutoff</span> <span class="o">=</span> <span class="mi">15</span>

<span class="c1"># The k most common words in the corpus. Use `high_cutoff` as the k.</span>
<span class="n">K_most_common</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">bow</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">high_cutoff</span><span class="p">)]</span>


<span class="n">filtered_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">freqs</span> <span class="k">if</span> <span class="p">(</span><span class="n">freqs</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">low_cutoff</span> <span class="ow">and</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">K_most_common</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">K_most_common</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">filtered_words</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['the', 'to', 'is', 'for', 'on', 'of', 'and', 'in', 'this', 'it', 'at', 'will', 'up', 'are', 'you']
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>98448</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Remove-Filtered-Words-from-Vocabulary">
<a class="anchor" href="#Remove-Filtered-Words-from-Vocabulary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Remove Filtered Words from Vocabulary<a class="anchor-link" href="#Remove-Filtered-Words-from-Vocabulary"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># A dictionary for the `filtered_words`. The key is the word and value is an id that represents the word.</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">filtered_words</span><span class="p">,</span> <span class="mi">1</span><span class="p">)}</span>

<span class="c1"># Reverse of the `vocab` dictionary. The key is word id and value is the word. </span>
<span class="n">id2vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">filtered_words</span><span class="p">,</span> <span class="mi">1</span><span class="p">)}</span>

<span class="c1"># tokenized with the words not in `filtered_words` removed.</span>
<span class="n">filtered</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">msg</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">filtered_words</span><span class="p">]</span> <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">tokenized</span><span class="p">)</span> <span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1499482/1499482 [2:13:51&lt;00:00, 186.69it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Balancing-the-classes">
<a class="anchor" href="#Balancing-the-classes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Balancing the classes<a class="anchor-link" href="#Balancing-the-classes"> </a>
</h3>
<p>If we look at how our twits are labeled, we'll find that 50% of them are neutral. This means that our network will be 45% accurate just by guessing 0 every single time. To help our network learn appropriately, we'll want to balance our classes.
That is, make sure each of our different sentiment scores show up roughly as frequently in the data.</p>
<p>What we can do here is go through each of our examples and randomly drop twits with neutral sentiment.  We want to get around 20% neutral twits starting from 50% neutral.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">sentiments</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">sentiments</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0: 0.08710474683924181
1: 0.11403071193918966
2: 0.44561321843143165
3: 0.20476004380179288
4: 0.14849127898834397
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">balanced</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'messages'</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">'sentiments'</span><span class="p">:[]}</span>

<span class="n">n_neutral</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">sentiments</span> <span class="k">if</span> <span class="n">each</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">N_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentiments</span><span class="p">)</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="p">(</span><span class="n">N_examples</span> <span class="o">-</span> <span class="n">n_neutral</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="o">/</span><span class="n">n_neutral</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'keep_prob: </span><span class="si">{</span><span class="n">keep_prob</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentiments</span><span class="p">):</span>
    <span class="n">message</span> <span class="o">=</span> <span class="n">filtered</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">sentiment</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">keep_prob</span><span class="p">:</span>
        <span class="n">balanced</span><span class="p">[</span><span class="s1">'messages'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
        <span class="n">balanced</span><span class="p">[</span><span class="s1">'sentiments'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentiment</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>keep_prob: 0.31102465021124265
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets check that we are balanced:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_neutral</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">balanced</span><span class="p">[</span><span class="s1">'sentiments'</span><span class="p">]</span> <span class="k">if</span> <span class="n">each</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">N_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">balanced</span><span class="p">[</span><span class="s1">'sentiments'</span><span class="p">])</span>
<span class="n">n_neutral</span><span class="o">/</span><span class="n">N_examples</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.1998550428903639</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks good, 1/5th of our samples are neutral now.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's convert our tokens into integer ids which we can pass to the network.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">token_ids</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">message</span><span class="p">]</span> <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">balanced</span><span class="p">[</span><span class="s1">'messages'</span><span class="p">]]</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="n">balanced</span><span class="p">[</span><span class="s1">'sentiments'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network">
<a class="anchor" href="#Neural-Network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Neural Network<a class="anchor-link" href="#Neural-Network"> </a>
</h2>
<p>With our vocabulary mapped to interger ids, we are now ready to build our neural network.</p>
<p>Here is a diagram showing the network:</p>
<h4 id="Embed--&gt;-RNN--&gt;-Dense--&gt;-Softmax">
<a class="anchor" href="#Embed--&gt;-RNN--&gt;-Dense--&gt;-Softmax" aria-hidden="true"><span class="octicon octicon-link"></span></a>Embed -&gt; RNN -&gt; Dense -&gt; Softmax<a class="anchor-link" href="#Embed--&gt;-RNN--&gt;-Dense--&gt;-Softmax"> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TextClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">lstm_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Initialize the model by setting up the layers.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            vocab_size : The vocabulary size.</span>
<span class="sd">            embed_size : The embedding layer size.</span>
<span class="sd">            lstm_size : The LSTM layer size.</span>
<span class="sd">            output_size : The output size.</span>
<span class="sd">            lstm_layers : The number of LSTM layers.</span>
<span class="sd">            dropout : The dropout probability.</span>
<span class="sd">        """</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span> <span class="o">=</span> <span class="n">lstm_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_layers</span> <span class="o">=</span> <span class="n">lstm_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="c1"># Setup embedding layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">lstm_layers</span><span class="p">,</span> 
                            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="c1"># Setup additional layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logsoftmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">""" </span>
<span class="sd">        Initializes hidden state</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            batch_size : The size of batches.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            hidden_state</span>
<span class="sd">            </span>
<span class="sd">        """</span>
        
        <span class="c1"># Create two new tensors with sizes n_layers x batch_size x hidden_dim,</span>
        <span class="c1"># initialized to zero, for hidden state and cell state of LSTM</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">data</span>
        
        <span class="n">hidden</span> <span class="o">=</span> <span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">(),</span>
                  <span class="n">weight</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">)</span><span class="o">.</span><span class="n">zero_</span><span class="p">())</span>
        
        <span class="k">return</span> <span class="n">hidden</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nn_input</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Perform a forward pass of our model on nn_input.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            nn_input : The batch of input to the NN.</span>
<span class="sd">            hidden_state : The LSTM hidden state.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            logps: log softmax output</span>
<span class="sd">            hidden_state: The new hidden state.</span>

<span class="sd">        """</span>
        <span class="c1"># embeddings and lstm_out</span>
        <span class="n">nn_input</span> <span class="o">=</span> <span class="n">nn_input</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">nn_input</span><span class="p">)</span>
        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">embeds</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">)</span>
        
        <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">lstm_out</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:]</span>
        
        <span class="c1"># dropout and fully-connected layer</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        
        <span class="n">logps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logsoftmax</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">logps</span><span class="p">,</span> <span class="n">hidden_state</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="View-Model">
<a class="anchor" href="#View-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>View Model<a class="anchor-link" href="#View-Model"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TextClassifier</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lstm_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">logps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">logps</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[-2.0672, -1.8099, -1.3161, -1.5152, -1.5058],
        [-2.0718, -1.7388, -1.3464, -1.5252, -1.5115],
        [-2.0702, -1.7568, -1.3375, -1.5287, -1.5054],
        [-2.0329, -1.9265, -1.2760, -1.5094, -1.4997]], grad_fn=&lt;LogSoftmaxBackward&gt;)
TextClassifier(
  (embedding): Embedding(98448, 10)
  (lstm): LSTM(10, 6, num_layers=2, dropout=0.1)
  (dropout): Dropout(p=0.1, inplace=False)
  (fc): Linear(in_features=6, out_features=5, bias=True)
  (logsoftmax): LogSoftmax(dim=1)
)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training">
<a class="anchor" href="#Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training<a class="anchor-link" href="#Training"> </a>
</h2>
<h3 id="DataLoaders-and-Batching">
<a class="anchor" href="#DataLoaders-and-Batching" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataLoaders and Batching<a class="anchor-link" href="#DataLoaders-and-Batching"> </a>
</h3>
<p>Now we should build a generator that we can use to loop through our data. It'll be more efficient if we can pass our sequences in as batches. Our input tensors should look like <code>(sequence_length, batch_size)</code>. So if our sequences are 40 tokens long and we pass in 25 sequences, then we'd have an input size of <code>(40, 25)</code>.</p>
<p>If we set our sequence length to 40, what do we do with messages that are more or less than 40 tokens? For messages with fewer than 40 tokens, we will pad the empty spots with zeros. We should be sure to <strong>left</strong> pad so that the RNN starts from nothing before going through the data. If the message has 20 tokens, then the first 20 spots of our 40 long sequence will be 0. If a message has more than 40 tokens, we'll just keep the first 40 tokens.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">dataloader</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">""" </span>
<span class="sd">    Build a dataloader.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">messages</span><span class="p">)))</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">messages</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>

    <span class="n">total_sequences</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">total_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">batch_messages</span> <span class="o">=</span> <span class="n">messages</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span> <span class="n">ii</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        
        <span class="c1"># First initialize a tensor of all zeros</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">sequence_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_messages</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_num</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_messages</span><span class="p">):</span>
            <span class="n">token_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
            <span class="c1"># Left pad!</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">sequence_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_tensor</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:,</span> <span class="n">batch_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_tensor</span><span class="p">[:</span><span class="n">sequence_length</span><span class="p">]</span>
        
        <span class="n">label_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span> <span class="n">ii</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_messages</span><span class="p">)])</span>
        
        <span class="k">yield</span> <span class="n">batch</span><span class="p">,</span> <span class="n">label_tensor</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-and--Validation">
<a class="anchor" href="#Training-and--Validation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training and  Validation<a class="anchor-link" href="#Training-and--Validation"> </a>
</h3>
<p>Split it into training and validation sets.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split_frac</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">split_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span><span class="o">*</span><span class="n">split_frac</span><span class="p">)</span>

<span class="n">train_features</span><span class="p">,</span> <span class="n">valid_features</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">token_ids</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
<span class="n">train_labels</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">sentiments</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">sentiments</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TextClassifier</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
<span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">logps</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">text_batch</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-model">
<a class="anchor" href="#Train-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train model<a class="anchor-link" href="#Train-model"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TextClassifier</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">lstm_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>TextClassifier(
  (embedding): Embedding(98449, 1024)
  (lstm): LSTM(1024, 512, num_layers=2, dropout=0.2)
  (dropout): Dropout(p=0.2, inplace=False)
  (fc): Linear(in_features=512, out_features=5, bias=True)
  (logsoftmax): LogSoftmax(dim=1)
)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">Train your model with dropout. Make sure to clip your gradients.</span>
<span class="sd">Print the training loss, validation loss, and validation accuracy for every 100 steps.</span>
<span class="sd">"""</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">001</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mi">5</span>


<span class="n">print_every</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_accs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Starting epoch </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">text_batch</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">(</span>
            <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># initialize hidden state</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="c1"># Set Device</span>
        <span class="n">text_batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">text_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">hidden</span><span class="p">:</span>
            <span class="n">each</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># reset gradients</span>
        <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
        <span class="c1"># get output from model</span>
        <span class="n">log_probs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text_batch</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        
        <span class="c1"># calculate the loss and perform backprop</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
        <span class="c1"># `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">steps</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            
            <span class="c1"># Get validation loss</span>
            <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">text_batch</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">(</span><span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span><span class="p">,</span>
                                                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">val_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                
                <span class="n">text_batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">text_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">val_hidden</span><span class="p">:</span>
                    <span class="n">each</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    
                <span class="n">val_log_probs</span><span class="p">,</span> <span class="n">test_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text_batch</span><span class="p">,</span> <span class="n">val_hidden</span><span class="p">)</span>
                <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">val_log_probs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                
                <span class="c1"># Accuracy</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">val_log_probs</span><span class="p">)</span>
                <span class="n">top_prob</span><span class="p">,</span> <span class="n">top_class</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">equality</span> <span class="o">=</span> <span class="n">top_class</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">top_class</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">equality</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">))</span>
            
            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">valid_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">valid_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_acc</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> / </span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Step: </span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
                  <span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">  Train Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
                  <span class="sa">f</span><span class="s1">'  Validation Loss: </span><span class="si">{</span><span class="n">valid_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
                  <span class="sa">f</span><span class="s1">'  Validation Accy: </span><span class="si">{</span><span class="n">valid_acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Starting epoch 1
Epoch: 1 / 3 	Step: 100 
  Train Loss: 0.913   Validation Loss: 0.956   Validation Accy: 0.634
Epoch: 1 / 3 	Step: 200 
  Train Loss: 0.856   Validation Loss: 0.877   Validation Accy: 0.658
Epoch: 1 / 3 	Step: 300 
  Train Loss: 0.781   Validation Loss: 0.841   Validation Accy: 0.670
Epoch: 1 / 3 	Step: 400 
  Train Loss: 0.783   Validation Loss: 0.724   Validation Accy: 0.716
Epoch: 1 / 3 	Step: 500 
  Train Loss: 0.745   Validation Loss: 0.761   Validation Accy: 0.713
Epoch: 1 / 3 	Step: 600 
  Train Loss: 0.738   Validation Loss: 0.706   Validation Accy: 0.725
Epoch: 1 / 3 	Step: 700 
  Train Loss: 0.722   Validation Loss: 0.688   Validation Accy: 0.746
Epoch: 1 / 3 	Step: 800 
  Train Loss: 0.730   Validation Loss: 0.752   Validation Accy: 0.714
Starting epoch 2
Epoch: 2 / 3 	Step: 100 
  Train Loss: 0.640   Validation Loss: 0.747   Validation Accy: 0.738
Epoch: 2 / 3 	Step: 200 
  Train Loss: 0.652   Validation Loss: 0.780   Validation Accy: 0.706
Epoch: 2 / 3 	Step: 300 
  Train Loss: 0.689   Validation Loss: 0.756   Validation Accy: 0.694
Epoch: 2 / 3 	Step: 400 
  Train Loss: 0.686   Validation Loss: 0.753   Validation Accy: 0.722
Epoch: 2 / 3 	Step: 500 
  Train Loss: 0.679   Validation Loss: 0.722   Validation Accy: 0.722
Epoch: 2 / 3 	Step: 600 
  Train Loss: 0.674   Validation Loss: 0.746   Validation Accy: 0.701
Epoch: 2 / 3 	Step: 700 
  Train Loss: 0.680   Validation Loss: 0.720   Validation Accy: 0.715
Epoch: 2 / 3 	Step: 800 
  Train Loss: 0.683   Validation Loss: 0.683   Validation Accy: 0.729
Starting epoch 3
Epoch: 3 / 3 	Step: 100 
  Train Loss: 0.600   Validation Loss: 0.756   Validation Accy: 0.704
Epoch: 3 / 3 	Step: 200 
  Train Loss: 0.602   Validation Loss: 0.733   Validation Accy: 0.731
Epoch: 3 / 3 	Step: 300 
  Train Loss: 0.615   Validation Loss: 0.744   Validation Accy: 0.722
Epoch: 3 / 3 	Step: 400 
  Train Loss: 0.625   Validation Loss: 0.716   Validation Accy: 0.719
Epoch: 3 / 3 	Step: 500 
  Train Loss: 0.563   Validation Loss: 0.758   Validation Accy: 0.694
Epoch: 3 / 3 	Step: 600 
  Train Loss: 0.663   Validation Loss: 0.760   Validation Accy: 0.716
Epoch: 3 / 3 	Step: 700 
  Train Loss: 0.587   Validation Loss: 0.698   Validation Accy: 0.719
Epoch: 3 / 3 	Step: 800 
  Train Loss: 0.666   Validation Loss: 0.689   Validation Accy: 0.716
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we get about 72% accuracy on the validation set.
Lets try the ULMFit approach</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ULMFit-approach">
<a class="anchor" href="#ULMFit-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>ULMFit approach<a class="anchor-link" href="#ULMFit-approach"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Import-Twits">
<a class="anchor" href="#Import-Twits" aria-hidden="true"><span class="octicon octicon-link"></span></a>Import Twits<a class="anchor-link" href="#Import-Twits"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="s1">'stocktwits_sentiment'</span><span class="p">,</span> <span class="s1">'twits.json'</span><span class="p">),</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">twits</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">twit</span><span class="p">[</span><span class="s1">'message_body'</span><span class="p">]</span> <span class="k">for</span> <span class="n">twit</span> <span class="ow">in</span> <span class="n">twits</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]]</span>
<span class="c1"># Since the sentiment scores are discrete, we'll scale the sentiments to 0 to 4 for use in our network</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="p">[</span><span class="n">twit</span><span class="p">[</span><span class="s1">'sentiment'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">twit</span> <span class="ow">in</span> <span class="n">twits</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocessing-the-Data">
<a class="anchor" href="#Preprocessing-the-Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocessing the Data<a class="anchor-link" href="#Preprocessing-the-Data"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For the preprocess step, fastai does a lot of the work for us using the Spacy tokenizer by default.  We keep track of uppercase letters so we do not lowercase everything.  Our preprocess function is therefore simplified.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">message</span><span class="p">):</span>
 
    <span class="n">text</span> <span class="o">=</span> <span class="n">message</span>
    
    <span class="c1"># Replace URLs with a space in the message</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'https?://[^\s]+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\$[a-zA-Z]*\b'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Replace StockTwits usernames with a space. The usernames are any word that starts with @.</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'@\w*\b'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># Replace everything not a letter with a space</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^a-zA-Z]'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Remove multiple spaces</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="c1"># Tokenize by splitting the string on whitespace into a list of words</span>
    <span class="c1">#tokens = text.split()</span>

    <span class="c1"># Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.</span>
    <span class="c1"># wnl = nltk.stem.WordNetLemmatizer()</span>
    <span class="c1"># tokens = [wnl.lemmatize(t) for t in tokens if len(t) &gt; 1]</span>
    
    <span class="k">return</span> <span class="n">text</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_clean</span> <span class="o">=</span> <span class="p">[</span><span class="n">preprocess</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">messages_clean</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="n">sentiments</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(['great buy at ill wait',
  '',
  'STAAnalystAlert for Jefferies Maintains with a rating of Hold setting target price at USD Our own verdict is Buy',
  'I heard there s a guy who knows someone who thinks somebody knows something on StockTwits',
  'reveal yourself',
  'Why the drop I warren Buffet taking out his position',
  'bears have reason on to pay more attention',
  'ok good we re not dropping in price over the weekend lol',
  'Daily Chart we need to get back to above',
  'drop per week after spike if no news in months back to s if BO then bingo what is the odds'],
 [4, 3, 4, 3, 2, 3, 0, 3, 4, 0])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">defaults</span><span class="o">.</span><span class="n">text_proc_rules</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;function fastai.text.core.fix_html&gt;,
 &lt;function fastai.text.core.replace_rep&gt;,
 &lt;function fastai.text.core.replace_wrep&gt;,
 &lt;function fastai.text.core.spec_add_spaces&gt;,
 &lt;function fastai.text.core.rm_useless_spaces&gt;,
 &lt;function fastai.text.core.replace_all_caps&gt;,
 &lt;function fastai.text.core.replace_maj&gt;,
 &lt;function fastai.text.core.lowercase&gt;]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-dataframe">
<a class="anchor" href="#Build-dataframe" aria-hidden="true"><span class="octicon octicon-link"></span></a>Build dataframe<a class="anchor-link" href="#Build-dataframe"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'messages'</span><span class="p">:</span> <span class="n">messages_clean</span><span class="p">,</span> <span class="s1">'sentiments'</span><span class="p">:</span> <span class="n">sentiments</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">);</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>messages</th>
      <th>sentiments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>great buy at ill wait</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td></td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>STAAnalystAlert for Jefferies Maintains with a rating of Hold setting target price at USD Our own verdict is Buy</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>I heard there s a guy who knows someone who thinks somebody knows something on StockTwits</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>reveal yourself</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Remove blank messages</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">'messages'</span><span class="p">]</span><span class="o">!=</span><span class="s1">''</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>messages</th>
      <th>sentiments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>great buy at ill wait</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>STAAnalystAlert for Jefferies Maintains with a rating of Hold setting target price at USD Our own verdict is Buy</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>I heard there s a guy who knows someone who thinks somebody knows something on StockTwits</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>reveal yourself</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Why the drop I warren Buffet taking out his position</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(1500631, 2)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Self-supervized-language-model">
<a class="anchor" href="#Self-supervized-language-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Self supervized language model<a class="anchor-link" href="#Self-supervized-language-model"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first step of the ULMFit approach is to build a language model.  A model that will predict the next word given the previous words.  This is <em>self supervized learning</em>.  So in a batch we have a text buffer as input and then the same buffer plus the next word as a target.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Text-data-loader">
<a class="anchor" href="#Text-data-loader" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text data loader<a class="anchor-link" href="#Text-data-loader"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TextDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">text_col</span><span class="o">=</span><span class="s1">'messages'</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s1">'sentiments'</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Look-at-the-data">
<a class="anchor" href="#Look-at-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Look at the data<a class="anchor-link" href="#Look-at-the-data"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>text_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos funny how these bears comes out today where were you yesterday when i was all alone getting flamed by these young bulls xxbos holey moley batman xxbos holding my waiting for kiki to tell me she loves me i mean jcpenney xxbos xxmaj china s xxmaj zhoushan city woos xxmaj exxon xxmaj mobil for a billion ethylene plant xxbos is max pain xxbos they are overselling again bring that xxup rsi</td>
      <td>funny how these bears comes out today where were you yesterday when i was all alone getting flamed by these young bulls xxbos holey moley batman xxbos holding my waiting for kiki to tell me she loves me i mean jcpenney xxbos xxmaj china s xxmaj zhoushan city woos xxmaj exxon xxmaj mobil for a billion ethylene plant xxbos is max pain xxbos they are overselling again bring that xxup rsi down</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxmaj volatility is expensive to forecast xxbos this is looking good xxbos wth xxbos about to break the daily high xxbos xxmaj all top ranks are xxup nvidia no others brands xxmaj see bounds back to xxbos people can run their fingers on the keyboard xxmaj xxunk and watch the chart you could learn a thing or two xxmaj now let s see premarket xxbos xxmaj update xxmaj aug xxmaj puts xxmaj</td>
      <td>volatility is expensive to forecast xxbos this is looking good xxbos wth xxbos about to break the daily high xxbos xxmaj all top ranks are xxup nvidia no others brands xxmaj see bounds back to xxbos people can run their fingers on the keyboard xxmaj xxunk and watch the chart you could learn a thing or two xxmaj now let s see premarket xxbos xxmaj update xxmaj aug xxmaj puts xxmaj up</td>
    </tr>
    <tr>
      <th>2</th>
      <td>unitedhealth xxmaj group s xxup pt raised by xxmaj raymond xxmaj james to strong buy rating xxbos xxmaj great summary of xxmaj boyar xxmaj value xxmaj group s xxmaj letter stay clear of xxup faang xxbos xxmaj absolutely ridiculous xxbos pump fake xxbos waiting to head to xxbos xxmaj it amuses me when bears here think they control the price with xxup st messages xxbos if i m wrong i m wrong</td>
      <td>xxmaj group s xxup pt raised by xxmaj raymond xxmaj james to strong buy rating xxbos xxmaj great summary of xxmaj boyar xxmaj value xxmaj group s xxmaj letter stay clear of xxup faang xxbos xxmaj absolutely ridiculous xxbos pump fake xxbos waiting to head to xxbos xxmaj it amuses me when bears here think they control the price with xxup st messages xxbos if i m wrong i m wrong i</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-language-learner">
<a class="anchor" href="#Create-language-learner" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create language learner<a class="anchor-link" href="#Create-language-learner"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With this data we can now fine tune the language model.
We will be using a recurrent neural network (RNN) using an architecture called AWD-LSTM</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">language_model_learner</span><span class="p">(</span>
    <span class="n">dls</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">Perplexity</span><span class="p">()])</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning-the-Language-Model">
<a class="anchor" href="#Fine-Tuning-the-Language-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fine-Tuning the Language Model<a class="anchor-link" href="#Fine-Tuning-the-Language-Model"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fit_one_cycle calls freeze when using a pretrained model so we are only training embeddings for words that are in our Stocktwits vocab, but aren't in the pretrained model vocab.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.973730</td>
      <td>3.781465</td>
      <td>0.368648</td>
      <td>43.880272</td>
      <td>19:35</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Continue-fine-tuning-the-model-after-unfreezing">
<a class="anchor" href="#Continue-fine-tuning-the-model-after-unfreezing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Continue fine-tuning the model after unfreezing<a class="anchor-link" href="#Continue-fine-tuning-the-model-after-unfreezing"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">2e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.667701</td>
      <td>3.579307</td>
      <td>0.391628</td>
      <td>35.848701</td>
      <td>22:17</td>
    </tr>
    <tr>
      <td>1</td>
      <td>3.556901</td>
      <td>3.493224</td>
      <td>0.401178</td>
      <td>32.891827</td>
      <td>22:18</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.501796</td>
      <td>3.440667</td>
      <td>0.407269</td>
      <td>31.207756</td>
      <td>22:08</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.429217</td>
      <td>3.405697</td>
      <td>0.411324</td>
      <td>30.135296</td>
      <td>21:58</td>
    </tr>
    <tr>
      <td>4</td>
      <td>3.346377</td>
      <td>3.383271</td>
      <td>0.414011</td>
      <td>29.466999</td>
      <td>22:09</td>
    </tr>
    <tr>
      <td>5</td>
      <td>3.297989</td>
      <td>3.370040</td>
      <td>0.416521</td>
      <td>29.079689</td>
      <td>22:22</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.222261</td>
      <td>3.362387</td>
      <td>0.418393</td>
      <td>28.858006</td>
      <td>22:10</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.179726</td>
      <td>3.362380</td>
      <td>0.419272</td>
      <td>28.857779</td>
      <td>22:16</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.155103</td>
      <td>3.368545</td>
      <td>0.419497</td>
      <td>29.036251</td>
      <td>22:22</td>
    </tr>
    <tr>
      <td>9</td>
      <td>3.091218</td>
      <td>3.374530</td>
      <td>0.419274</td>
      <td>29.210562</td>
      <td>22:23</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Display-the-RNN-layers">
<a class="anchor" href="#Display-the-RNN-layers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Display the RNN layers<a class="anchor-link" href="#Display-the-RNN-layers"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SequentialRNN (Input shape: ['64 x 72'])
================================================================
Layer (type)         Output Shape         Param #    Trainable 
================================================================
RNNDropout           64 x 72 x 400        0          False     
________________________________________________________________
RNNDropout           64 x 72 x 1152       0          False     
________________________________________________________________
RNNDropout           64 x 72 x 1152       0          False     
________________________________________________________________
Linear               64 x 72 x 39784      15,953,384 True      
________________________________________________________________
RNNDropout           64 x 72 x 400        0          False     
________________________________________________________________

Total params: 15,953,384
Total trainable params: 15,953,384
Total non-trainable params: 0

Optimizer used: &lt;function Adam at 0x7fc7a15836a8&gt;
Loss function: FlattenedLoss of CrossEntropyLoss()

Model frozen up to parameter group #3

Callbacks:
  - ModelResetter
  - RNNRegularizer
  - ModelToHalf
  - TrainEvalCallback
  - Recorder
  - ProgressCallback
  - MixedPrecision</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-our-basic-language-model">
<a class="anchor" href="#Test-our-basic-language-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test our basic language model<a class="anchor-link" href="#Test-our-basic-language-model"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now have a language model originally trained on Wikipedia data trained with Stocktwits data.  The goal is to predict the sentiment of messages but lets look at what this basic language model has learned</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">TEXT</span> <span class="o">=</span> <span class="s2">"Earnings were above expectations. This stock should be trending up."</span>
<span class="n">N_WORDS</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">N_SENTENCES</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">N_WORDS</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span> 
         <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_SENTENCES</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Earnings were above expectations xxunk This stock should be trending up xxunk Update Aug Calls Up to per contract since alerted on Jul days to expire Some of todays top open interest changes Update Sep Puts Up sincealerted on
Earnings were above expectations xxunk This stock should be trending up xxunk Lot of Buying New Insider Filing On THICC JOHN days Transaction Code Both the short term and long term trends are positive This is a very
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="-">
<a class="anchor" href="#-" aria-hidden="true"><span class="octicon octicon-link"></span></a> <a class="anchor-link" href="#-"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Classifier-for-Stocktwits-sentiments">
<a class="anchor" href="#Classifier-for-Stocktwits-sentiments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Classifier for Stocktwits sentiments<a class="anchor-link" href="#Classifier-for-Stocktwits-sentiments"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now train our model with the sentiment label using our language model as a starting point.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-the-data-loader-with-sentiment-labels">
<a class="anchor" href="#Create-the-data-loader-with-sentiment-labels" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create the data loader with sentiment labels<a class="anchor-link" href="#Create-the-data-loader-with-sentiment-labels"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls_clas</span> <span class="o">=</span> <span class="n">TextDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">text_col</span><span class="o">=</span><span class="s1">'messages'</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s1">'sentiments'</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">dls_clas</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos i xxup want xxup him xxup to xxup feel xxup max xxup pain xxup the xxup rest xxup ill xxup play xxup by xxup play xxup it xxup same xxup as xxup amd xxup at xxup exp xxup why xxup it xxup had xxup to xxup hit xxup then xxup it xxup did xxup lulu xxup wk b xxup ibm b</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxup the xxup xxunk xxup fucks xxup are xxup waiting xxup for xxup mu xxup to xxup go xxup below xxup to xxup buy xxup it xxup back xxup lets xxup just xxup all xxup max xxup out xxup our xxup credit xxup cards xxup and xxup buy xxup more xxup mu xxup at xxup this xxup low xxpad xxpad xxpad</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos lookslike xxmaj about xxup mm s xxmaj trying xxmaj to xxmaj hold xxup bid xxmaj in xxmaj low s xxmaj but xxup mm xxmaj forcing xxmaj trading xxmaj in xxmaj low s xxup jpm xxmaj tusa lol xxmaj glta xxmaj bulls xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id='Create-the-learner-to-classify-our-"Twits"'>
<a class="anchor" href="#Create-the-learner-to-classify-our-" twits aria-hidden="true"><span class="octicon octicon-link"></span></a>Create the learner to classify our "Twits"<a class="anchor-link" href="#Create-the-learner-to-classify-our-%22Twits%22"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls_clas</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                                <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fine-tuning-the-classifier">
<a class="anchor" href="#Fine-tuning-the-classifier" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fine tuning the classifier<a class="anchor-link" href="#Fine-tuning-the-classifier"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now train our model with discriminative learning rates and gradual unfreezing.
For NLP classifiers, the fastai library authors found that unfreezing a few layers at a time makes a real difference</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.415620</td>
      <td>1.161403</td>
      <td>0.529711</td>
      <td>14:30</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.976749</td>
      <td>0.891179</td>
      <td>0.661879</td>
      <td>15:38</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze_to</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">5e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">5e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.819692</td>
      <td>0.752725</td>
      <td>0.720497</td>
      <td>16:02</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-3</span><span class="o">/</span><span class="p">(</span><span class="mf">2.6</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span><span class="mf">1e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.777341</td>
      <td>0.734695</td>
      <td>0.725702</td>
      <td>16:32</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.743741</td>
      <td>0.660567</td>
      <td>0.757402</td>
      <td>16:44</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.675439</td>
      <td>0.628990</td>
      <td>0.769650</td>
      <td>16:24</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.640707</td>
      <td>0.613024</td>
      <td>0.775841</td>
      <td>16:08</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.641090</td>
      <td>0.602056</td>
      <td>0.779922</td>
      <td>15:50</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.630175</td>
      <td>0.593337</td>
      <td>0.782618</td>
      <td>15:47</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.622346</td>
      <td>0.590662</td>
      <td>0.783731</td>
      <td>15:44</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.604861</td>
      <td>0.592279</td>
      <td>0.783621</td>
      <td>15:49</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.596378</td>
      <td>0.589263</td>
      <td>0.785593</td>
      <td>15:58</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.574639</td>
      <td>0.588258</td>
      <td>0.784964</td>
      <td>16:14</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Predictions-with-the-ULMFit-model">
<a class="anchor" href="#Predictions-with-the-ULMFit-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Predictions with the ULMFit model<a class="anchor-link" href="#Predictions-with-the-ULMFit-model"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>0: very negative</li>
<li>1: negative</li>
<li>2: neutral</li>
<li>3: positive</li>
<li>4: very positive</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">'$AAPL doing my part. Just bought my first iPad'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('4',
 tensor(4),
 tensor([4.7856e-04, 2.6827e-02, 4.5500e-02, 5.6848e-02, 8.7035e-01]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">'$AAPL historic reversal selloff on news , historic crash news'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('0',
 tensor(0),
 tensor([9.7967e-01, 2.6304e-04, 1.2899e-02, 7.1583e-03, 4.8937e-06]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">'$AAPL well that was a good trade'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('2', tensor(2), tensor([0.0092, 0.0419, 0.7770, 0.1612, 0.0107]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">'Sold my $AAPL 10/16 $120c this morning and MAN I&amp;#39;m glad I&amp;#39;m out of there!</span><span class="se">\n\n</span><span class="s1">Although, this was one of my favorite trades,  holding through the volatility last week was ROUGH and I didn&amp;#39;t want to be caught holding the bag (after the iPhone event)</span><span class="se">\n\n</span><span class="s1">What&amp;#39;s next? since $SPY  making a new high... Might looks for some shorts now 🐻🐻🐻'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('3',
 tensor(3),
 tensor([4.4554e-04, 4.8995e-02, 3.4516e-01, 6.0069e-01, 4.7157e-03]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">'$AAPL the news already leaked. Nothing new just a battery that last an extra hour and the 5G. They are going to launch 4 phones. Probably this time they will introduce the middle finger option to unlock the phone. To make the idiots happy that they brought something new. Lol'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('2',
 tensor(2),
 tensor([1.2910e-04, 1.0833e-02, 8.2918e-01, 1.5977e-01, 8.7016e-05]))</pre>
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="sylvaint/aimusing"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ai%20for%20trading/ulmfit/stocktwits/2020/10/20/fastai_ulmfit_vs_pytorch_stocktwits.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My journey applying AI to quant trading.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/sylvaint" title="sylvaint"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/greytrader" title="greytrader"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
